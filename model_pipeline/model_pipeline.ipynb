{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7654e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/passwd/group-5/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"image.png\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ad296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "import os, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 10\n",
    "\n",
    "height, width = image.size[1], image.size[0]\n",
    "print(f\"Image size: {width}x{height}\")\n",
    "\n",
    "checkpoint_path = \"sam_vit_b_01ec64.pth\"\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "    urllib.request.urlretrieve(url, checkpoint_path)\n",
    "\n",
    "\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=checkpoint_path)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam.to(device)\n",
    "print(f\"SAM loaded on {device}\")\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=16,\n",
    "    pred_iou_thresh=0.7,\n",
    "    stability_score_thresh=0.85,\n",
    "    min_mask_region_area=500,\n",
    ")\n",
    "\n",
    "print(\"Generating masks...\")\n",
    "masks = mask_generator.generate(np.array(image))\n",
    "masks_sorted = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
    "\n",
    "predicted_panoptic_map = np.zeros((height, width), dtype=np.int32)\n",
    "for idx, mask_data in enumerate(masks_sorted[:TOP_N]):\n",
    "    predicted_panoptic_map[mask_data['segmentation']] = idx + 1\n",
    "\n",
    "predicted_panoptic_map = torch.from_numpy(predicted_panoptic_map)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_panoptic_map, cmap=f'tab20', interpolation='nearest')\n",
    "plt.title(f'SAM Segmentation ({len(masks_sorted[:TOP_N])} segments)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tf\n",
    "import torch\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tf.Compose([tf.PILToTensor()])\n",
    "img_tensor = transform(image)\n",
    "\n",
    "def get_mask_box(tensor: torch.Tensor) -> tuple:\n",
    "    \"\"\"\n",
    "    Get part of the bounding box of the non-zero elements in a tensor.\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor.\n",
    "    Returns:\n",
    "        tuple: (first_n, last_n) where first_n is the index of the first non-zero element,\n",
    "               and last_n is the index of the last non-zero element.\n",
    "    \"\"\"\n",
    "\n",
    "    non_zero_indices = torch.nonzero(tensor, as_tuple=True)[0]\n",
    "    if non_zero_indices.shape[0] == 0:\n",
    "        return None, None\n",
    "    first_n = non_zero_indices[:1].item()\n",
    "    last_n = non_zero_indices[-1:].item()\n",
    "\n",
    "    return first_n, last_n\n",
    "\n",
    "segments = []\n",
    "for label in predicted_panoptic_map.unique():\n",
    "    \n",
    "    y_start, y_end = get_mask_box(predicted_panoptic_map==label)\n",
    "    x_start, x_end = get_mask_box((predicted_panoptic_map==label).T)\n",
    "\n",
    "    cropped_tensor = img_tensor[:, y_start:y_end+1, x_start:x_end+1]\n",
    "    cropped_mask = predicted_panoptic_map[y_start:y_end+1, x_start:x_end+1] == label\n",
    "\n",
    "    segment = cropped_tensor * cropped_mask.unsqueeze(0)\n",
    "    segment[:, ~cropped_mask] = 188\n",
    "\n",
    "    segments.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ffa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "class_model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de759dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = []\n",
    "\n",
    "for segment in segments:\n",
    "    inputs = image_processor(images=segment, return_tensors=\"pt\")\n",
    "    outputs = class_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    predicted_class = class_model.config.id2label[predicted_class_idx]\n",
    "    predicted_classes.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f509c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e857a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classifier = pipeline(\"zero-shot-classification\", model=\"typeform/distilbert-base-uncased-mnli\")\n",
    "candidate_labels = [\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"tree\",\n",
    "    \"dog\",\n",
    "    \"building\",\n",
    "    \"person\",\n",
    "    \"sky\",\n",
    "    \"ground\",\n",
    "    \"hardware\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a54eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    result = label_classifier(predicted_class, candidate_labels=candidate_labels)\n",
    "    label = result['labels'][0] \n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment, label, predicted_class in zip(segments, labels, predicted_classes):\n",
    "    plt.imshow(segment.permute(1, 2, 0).numpy().astype(int))\n",
    "    plt.title(f\"Predicted Class: {predicted_class}, Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
